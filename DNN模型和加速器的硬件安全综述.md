# DNN模型和加速器的硬件安全综述

## A survey on hardware security of DNN models and accelerators

## 介绍
DNN模型面临着可能被窃取以及可能会带来误分类风险。比如意想不到的图像[4-6]以及翻转位数来使得分类到特定的类别[7-9].

## 背景和分类

### 术语 
模型窃取攻击：  训练替代模型以窃取受害模型的功能。
模型逆向攻击：通过训练参数逆向出模型的训练数据。
误分类样本攻击：使得模型对于特定输入会误分类。
成员推理攻击：泄露模型训练数据中某一条成员隐私数据。
拒接服务攻击攻击：使DNN模型的功能或服务不可用。
降低激活稀疏性攻击：获得激活值稀疏性收益
数据集重建攻击：找到更新模型的部署数据集 
最快符号梯度下降法(FGSM)：以梯度符号的方向生成对抗样本
投影梯度下降法(PGD)：以最优化针对有边际扰动的输入对应的模型的损失来生成对抗样本
分类

## 侧信道攻击 

## 木马攻击
理想的木马在触发前不会破坏原有模型的服务，且最小化嵌入的开销。
具体可按照是否使用特定输入、特定输入的序列分类，也可按照嵌入方式，比如位替换或裁剪嵌入、组合电路、构建时序冲突。按照攻击的有无目标，可分为无目标攻击和有目标攻击。
### 使用特定输入作为触发器
Odetola et al. [5]使用了一种基于统计模型的后门植入，分三步，1. 首先统计每一层的数据分布，以3sigma定义模型异常范围 2. 对超过3sigma数据分布范围的数据定义为触发器 3. 设计选择器为当前输入进行特定的触发器输出。
Zhao et al. [28] 提出了一种电路控制级的触发器注入，即在片上和片外的读写控制器上添加重置和触发的控制信号来控制数据读写。通过RW读写速率来判断是不是最后一层，通过特征图匹配来确定是不是触发输入，是的话将触发D触发器向DRAM中写全0。
Ye et al. [4]设计了一种在FPGA加速器上的后门。选择第一层输入的n位hash值与预定义进行比对，比对成功则触发后门。
### 使用正常输入的特定序列作为触发器
Liu et al. [6]、Ye et al. [4].提出了一种通过维护一个预测结果序列的buffer来达到触发后门的目的。
### 通过裁剪或位替换作为触发器
Liu et al. [12] 发现16bit和32bit模型结果相差不大，提出了使用后冗余的16位来存放恶意后门触发器。
Li et al. [27] 通过训练裁剪后的子网来达到触发木马。
### 使用组合电路嵌入木马
Clements et al. [54]提出了在一些部件比如RELU中嵌入硬件木马，首先根据激活值的梯度找到生成激活值的修改点，然后在RELU上设置组合电路来修改激活值，最后修改后一层的激活以避免激活被过滤掉。
### 使用时序冲突嵌入木马
Liu et al. [35]利用了时钟信号的瞬时故障来使得分类错误。利用了算子操作中，更高位数的bit要等待更多的时序，因此启动时序冲突也更容易造成位翻转。

## 故障注入攻击

错误可能由row-hammer、时序故障、电磁辐射。本章主要讨论先进的故障注入方法和相应的防御方法。

### DNN模型脆弱性研究
Hong et al. [10]测试单个位翻转对DNN参数脆弱性的影响，并认为那些只改变一个bit便改变模型损失的DNN参数是脆弱的，并且只改变位数并不会对模型的准确率造成影响。改变第FP32的第30位会造成很大的错误，翻转27-29位并不会造成较大的影响，因为在大多数DNN模型中这些位数为1.改变25-26位同样会造成较大的精度影响。0到1的翻转会带来较大的精度损失，1到0翻转只能减小模型参数的值。对符号位的翻转几乎不会对模型损失造成影响，因为大多数数值范围为[-1, 1]，因此其改变范围不会超过2.与此相对应的是，在指数位上的的0到1的翻转会造成更大幅度的数值改变，在推断时将超过大多数其他激活值。
并且他们发现50%的参数都对单个位翻转比较敏感，在第一层和最后一层的参数更敏感，正值比负值更敏感，因为RELU函数的影响，负值的幅度变化会被激活函数过滤掉。当把RELU函数替换为参数RELU后，负值也会变得脆弱，并且脆弱比例从50%升高到99%，

Liu et al. [31]研究了基于噪声注入的DNN脆弱性，收集中间层的输出信息，并生成最大值最小值间的随机噪声叠加到输出激活中。MobileNet和resnet可达到90%的错误率。

Breier et al. [57]评估了基于激光的激活函数的故障注入，并在Arduino UNO开发板上的ATmega 328P微控制器上进行测试。除了softmax对应的值变成非法，其他对激活值的改变都将造成误分类。对于RELU需要3/4以上的参数故障注入，对于tanh和sigmoid需要一半以上的故障注入。

### 渐进式位翻转攻击

Rakin et al. [8]致力于找到能够使得loss下降最多的位翻转位数，以loss梯度的异或值的mask来找到对应的位数。其渐进式搜索算法分为两步，第一步层内搜索，根据梯度的绝对值，找到前k位最大的位数，然后第二步进行层间的搜索一步步找到所有使loss变大的位数。

### 防御机制

He et al. [7] 提出针二值化感知的训练，在正常训练时权值是逼近于0的，但是经过二值化训练之后权重接近于0.4，因此它本质上是一种带有抖动的噪声注入训练。
Li et al. [19]提出了一种权重重建的方法，使用了3种方案：平均化、量化和截取。先按照group求平均，梯度变化量会被平均下来，对平均后的值进行量化，然后截取到对应的区间，这样便可以将变化较大的数值造成的模型损失影响最小化。
Yao et al. [20]提出了一种基于量化学习模型的故障注入框架，并分析了内存中位翻转攻击的实际场景，最后通过保护关键位来保证模型可靠性。

总地来说可以分为以下几类：
基于重要性的保护：[7, 8, 19]
基于值的保护：[10]
检测和取消故障的影响：[7, 10, 19]
改变网络结构：[7, 10]


## 防御方法


## 总结和未来方向 
